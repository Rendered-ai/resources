{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "603f3ab7",
   "metadata": {},
   "source": [
    "# Getting started with Rendered.ai Datasets\n",
    "\n",
    "Objective: Learn about how to access and use Datasets with the SDK. To follow along, use the `default` cotent code when registering on the Platform or create a new workspace with this code.\n",
    "\n",
    "Reference the latest SDK Documentation at https://sdk.rendered.ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2a6ce3",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "A Dataset is a variable collection of output images or video, masks, annotation, and other metadata that has been created by execution of a Job. To learn more information, read through the [Terminology guide](https://support.rendered.ai/rd/Terminology.1589379085.html) or the [Working with Datasets Tutorial](https://support.rendered.ai/rd/Working-With-Datasets.1577123882.html).\n",
    "\n",
    "There are several types of jobs that can be run with the Rendered.ai Platform, and creating a Dataset starts a type of job.\n",
    "\n",
    "All users of a workspace can:\n",
    "- View a list of existing datasets and running dataset jobs with `get_datasets()`\n",
    "- Create a new dataset with a staged graph with `create_dataset()`. This will kick off a dataset job that can be monitored.\n",
    "- Stop a running dataset job with `cancel_dataset()`\n",
    "- Download the dataset files of a completed dataset job with `download_dataset()`\n",
    "- Edit a dataset description with `edit_dataset()`\n",
    "- Delete an existing dataset with `delete_dataset()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3f3730",
   "metadata": {},
   "source": [
    "### Get the latest `anatools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73defe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install anatools --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faca5644",
   "metadata": {},
   "source": [
    "### Set up imports and log into the SDK\n",
    "These imports are required for this Notebook to run. \n",
    "Enter your credentials at the prompts. Logging in successfully will list the organizations and workspaces you have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "638c333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import json\n",
    "import pprint\n",
    "import time \n",
    "import anatools\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb6b48b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your credentials for the Rendered.ai Platform.\n",
      "Email: email@rendered.ai\n",
      "········\n",
      "These are your organizations and workspaces:\n",
      "    default Organization                          e8af8e7e-60d3-415f-a88d-9f4e191afec4              \n",
      "\tExample                                   c721696e-648f-4572-a9ca-5dd72f1e8f58              \n",
      "The current workspaces is: c721696e-648f-4572-a9ca-5dd72f1e8f58\n"
     ]
    }
   ],
   "source": [
    "sdk = anatools.client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90572286",
   "metadata": {},
   "source": [
    "### View Datasets\n",
    "Use `get_datasets()` to view information about the datasets that have been previously created in the workspace.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dcec3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'datasetId': '040242b6-968f-4506-b20a-955a00ab0f2b',\n",
       "  'name': 'EverythingUniform',\n",
       "  'channel': 'example',\n",
       "  'graphId': 'eb8ce701-3925-4ef9-9764-d15441734301',\n",
       "  'interpretations': '10',\n",
       "  'user': 'email@rendered.ai',\n",
       "  'type': 'synthetic',\n",
       "  'status': 'complete',\n",
       "  'priority': '1',\n",
       "  'seed': '421997119',\n",
       "  'count': '10',\n",
       "  'files': '10',\n",
       "  'size': '36262918',\n",
       "  'description': ''},\n",
       " {'datasetId': '1796fb4c-fee6-4af4-8e49-d70d9e58255a',\n",
       "  'name': '200runs_5objectScene',\n",
       "  'channel': 'example',\n",
       "  'graphId': '0047b170-8250-4cd8-8052-1fbee99d07fb',\n",
       "  'interpretations': '200',\n",
       "  'user': 'email@rendered.ai',\n",
       "  'type': 'synthetic',\n",
       "  'status': 'complete',\n",
       "  'priority': '3',\n",
       "  'seed': '307539751',\n",
       "  'count': '200',\n",
       "  'files': '200',\n",
       "  'size': '574636064',\n",
       "  'description': '5 objects per scene: very low obstruction'},\n",
       " {'datasetId': '3bcb3991-239e-4522-a8b3-76a068f6ba0a',\n",
       "  'name': '200runs_100objectScene',\n",
       "  'channel': 'example',\n",
       "  'graphId': '3821936c-3ddf-4aca-8e5c-2023e6a8101b',\n",
       "  'interpretations': '200',\n",
       "  'user': 'email@rendered.ai',\n",
       "  'type': 'synthetic',\n",
       "  'status': 'complete',\n",
       "  'priority': '3',\n",
       "  'seed': '256366860',\n",
       "  'count': '200',\n",
       "  'files': '200',\n",
       "  'size': '740335166',\n",
       "  'description': '100 objects per scene: very high obstruction'},\n",
       " {'datasetId': '441d8e60-2c86-42fe-9743-8f4ba7a4a52b',\n",
       "  'name': '1000runs_15objectScene',\n",
       "  'channel': 'example',\n",
       "  'graphId': 'fc183d84-c13a-4f15-8875-c10b5b35076d',\n",
       "  'interpretations': '1000',\n",
       "  'user': 'email@rendered.ai',\n",
       "  'type': 'synthetic',\n",
       "  'status': 'complete',\n",
       "  'priority': '3',\n",
       "  'seed': '593185',\n",
       "  'count': '1000',\n",
       "  'files': '1000',\n",
       "  'size': '3088354461',\n",
       "  'description': '15 objects per scene: low obstruction'},\n",
       " {'datasetId': '6f043f33-604e-4f1e-bde1-e59c1cee41fc',\n",
       "  'name': 'EverythingUniform',\n",
       "  'channel': 'example',\n",
       "  'graphId': '70177122-0668-402b-a9c5-cdf6dea97f28',\n",
       "  'interpretations': '10',\n",
       "  'user': 'email@rendered.ai',\n",
       "  'type': 'synthetic',\n",
       "  'status': 'complete',\n",
       "  'priority': '1',\n",
       "  'seed': '484575286',\n",
       "  'count': '10',\n",
       "  'files': '10',\n",
       "  'size': '35818905',\n",
       "  'description': '10 runs of the Everything is Uniform graph'},\n",
       " {'datasetId': '87f25d6a-73a0-4142-9815-3a9ed1d02339',\n",
       "  'name': '200runs_200objectScene',\n",
       "  'channel': 'example',\n",
       "  'graphId': 'f9bb3d3e-dbaf-4113-8b00-696271c8667a',\n",
       "  'interpretations': '200',\n",
       "  'user': 'email@rendered.ai',\n",
       "  'type': 'synthetic',\n",
       "  'status': 'complete',\n",
       "  'priority': '3',\n",
       "  'seed': '711873787',\n",
       "  'count': '200',\n",
       "  'files': '200',\n",
       "  'size': '777311539',\n",
       "  'description': '200 objects per scene: very high obstruction'},\n",
       " {'datasetId': 'a79cf7a9-7b33-42b4-89ce-12fc2838ec63',\n",
       "  'name': '200runs_10objectScene',\n",
       "  'channel': 'example',\n",
       "  'graphId': '0da7340b-1a84-480c-bc5c-de8667ad4b32',\n",
       "  'interpretations': '200',\n",
       "  'user': 'email@rendered.ai',\n",
       "  'type': 'synthetic',\n",
       "  'status': 'complete',\n",
       "  'priority': '3',\n",
       "  'seed': '851836536',\n",
       "  'count': '200',\n",
       "  'files': '200',\n",
       "  'size': '601233507',\n",
       "  'description': '10 objects per scene: low obstruction'},\n",
       " {'datasetId': 'cdc89b97-4052-41e1-ad39-78a54d3e3d12',\n",
       "  'name': '200runs_40objectScene',\n",
       "  'channel': 'example',\n",
       "  'graphId': 'db38d803-b613-4b07-aeba-0b8f7f8b8298',\n",
       "  'interpretations': '200',\n",
       "  'user': 'email@rendered.ai',\n",
       "  'type': 'synthetic',\n",
       "  'status': 'complete',\n",
       "  'priority': '3',\n",
       "  'seed': '292097078',\n",
       "  'count': '200',\n",
       "  'files': '200',\n",
       "  'size': '677921626',\n",
       "  'description': '40 objects per scene: moderate obstruction'},\n",
       " {'datasetId': 'd5a2c898-2f01-48a7-9e62-c922da60b780',\n",
       "  'name': '200runs_70objectScene',\n",
       "  'channel': 'example',\n",
       "  'graphId': '9bea72e7-0f55-438c-9490-7a28450a7ca6',\n",
       "  'interpretations': '200',\n",
       "  'user': 'email@rendered.ai',\n",
       "  'type': 'synthetic',\n",
       "  'status': 'complete',\n",
       "  'priority': '3',\n",
       "  'seed': '69929220',\n",
       "  'count': '200',\n",
       "  'files': '200',\n",
       "  'size': '721184116',\n",
       "  'description': '70 objects per scene: high obstruction'},\n",
       " {'datasetId': 'e436fe6f-1d6a-4ee4-bc86-c91226be7a6c',\n",
       "  'name': 'ToysinBoxes',\n",
       "  'channel': 'example',\n",
       "  'graphId': 'd8d9b2e7-2cb1-401a-bc89-0e8bb9951782',\n",
       "  'interpretations': '50',\n",
       "  'user': 'email@rendered.ai',\n",
       "  'type': 'synthetic',\n",
       "  'status': 'complete',\n",
       "  'priority': '3',\n",
       "  'seed': '591192916',\n",
       "  'count': '50',\n",
       "  'files': '50',\n",
       "  'size': '80942475',\n",
       "  'description': '50 Samples of the Rendered.ai example channel default graph.'},\n",
       " {'datasetId': 'f611aa13-e64e-4a93-9b71-9862c9bc1056',\n",
       "  'name': '200runs_15objectScene',\n",
       "  'channel': 'example',\n",
       "  'graphId': 'fc183d84-c13a-4f15-8875-c10b5b35076d',\n",
       "  'interpretations': '200',\n",
       "  'user': 'email@rendered.ai',\n",
       "  'type': 'synthetic',\n",
       "  'status': 'complete',\n",
       "  'priority': '3',\n",
       "  'seed': '960334187',\n",
       "  'count': '200',\n",
       "  'files': '200',\n",
       "  'size': '616914245',\n",
       "  'description': '15 objects per scene: low obstruction'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdk.get_datasets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
